{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6818a4c6",
   "metadata": {},
   "source": [
    "# SVM Model with scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfbe9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from svm_scratch import LinearSVM_Dual\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa6a8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_val = pd.read_csv('../X_test_encoded.csv')\n",
    "df_train = pd.read_csv('../X_train_encoded.csv')\n",
    "X_val = df_val.drop('Depression', axis=1)\n",
    "y_val = df_val['Depression']\n",
    "X = df_train.drop('Depression', axis=1)\n",
    "y = df_train['Depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4c6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'svm__C': 1}\n",
      "Best cross-validation accuracy: 0.8466706741290597\n",
      "\n",
      "Validation Set Results:\n",
      "Accuracy on validation set: 0.8469534050179212\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8336    0.7882    0.8102      2313\n",
      "           1     0.8556    0.8886    0.8718      3267\n",
      "\n",
      "    accuracy                         0.8470      5580\n",
      "   macro avg     0.8446    0.8384    0.8410      5580\n",
      "weighted avg     0.8465    0.8470    0.8463      5580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create pipeline with MinMaxScaler and SVM\n",
    "pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('svm', SVC(kernel='linear', random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid for pipeline\n",
    "param_grid = {\n",
    "    'svm__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Use pipeline in GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Use best model and evaluate on validation set\n",
    "best_model = grid_search.best_estimator_\n",
    "val_predictions = best_model.predict(X_val)\n",
    "\n",
    "# Print validation results\n",
    "print(\"\\nValidation Set Results:\")\n",
    "print(\"Accuracy on validation set:\", accuracy_score(y_val, val_predictions))\n",
    "print(\"\\nClassification Report on Validation Set:\")\n",
    "print(classification_report(y_val, val_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdfa4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ../model_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_class0</th>\n",
       "      <th>recall_class0</th>\n",
       "      <th>f1_class0</th>\n",
       "      <th>precision_class1</th>\n",
       "      <th>recall_class1</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>f1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>0.846953</td>\n",
       "      <td>0.833562</td>\n",
       "      <td>0.788154</td>\n",
       "      <td>0.810222</td>\n",
       "      <td>0.855585</td>\n",
       "      <td>0.888583</td>\n",
       "      <td>0.871772</td>\n",
       "      <td>0.844573</td>\n",
       "      <td>0.838368</td>\n",
       "      <td>0.840997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  accuracy  precision_class0  recall_class0  f1_class0  \\\n",
       "0  SVM_Linear  0.846953          0.833562       0.788154   0.810222   \n",
       "\n",
       "   precision_class1  recall_class1  f1_class1  precision_avg  recall_avg  \\\n",
       "0          0.855585       0.888583   0.871772       0.844573    0.838368   \n",
       "\n",
       "     f1_avg  \n",
       "0  0.840997  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# After getting predictions and running classification_report\n",
    "def save_metrics_to_csv(model_name, y_true, y_pred, filepath='../model_metrics.csv'):\n",
    "    \"\"\"\n",
    "    Save model metrics to CSV file with each model as a row\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name : str\n",
    "        Name of the model\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_pred : array-like\n",
    "        Predicted labels\n",
    "    filepath : str\n",
    "        Path to CSV file\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Class 0 metrics\n",
    "    precision_0 = precision_score(y_true, y_pred, pos_label=0)\n",
    "    recall_0 = recall_score(y_true, y_pred, pos_label=0)\n",
    "    f1_0 = f1_score(y_true, y_pred, pos_label=0)\n",
    "    \n",
    "    # Class 1 metrics\n",
    "    precision_1 = precision_score(y_true, y_pred, pos_label=1)\n",
    "    recall_1 = recall_score(y_true, y_pred, pos_label=1)\n",
    "    f1_1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "    \n",
    "    # Average metrics\n",
    "    precision_avg = precision_score(y_true, y_pred, average='macro')\n",
    "    recall_avg = recall_score(y_true, y_pred, average='macro')\n",
    "    f1_avg = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # Create a dictionary with all metrics\n",
    "    metrics_dict = {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_class0': precision_0,\n",
    "        'recall_class0': recall_0,\n",
    "        'f1_class0': f1_0,\n",
    "        'precision_class1': precision_1,\n",
    "        'recall_class1': recall_1,\n",
    "        'f1_class1': f1_1,\n",
    "        'precision_avg': precision_avg,\n",
    "        'recall_avg': recall_avg,\n",
    "        'f1_avg': f1_avg\n",
    "    }\n",
    "    \n",
    "    # Check if file exists\n",
    "    if os.path.exists(filepath):\n",
    "        # Read existing data and append new row\n",
    "        metrics_df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Check if model already exists in the dataframe\n",
    "        if model_name in metrics_df['model'].values:\n",
    "            # Update existing row\n",
    "            metrics_df.loc[metrics_df['model'] == model_name] = pd.Series(metrics_dict)\n",
    "        else:\n",
    "            # Append new row\n",
    "            metrics_df = pd.concat([metrics_df, pd.DataFrame([metrics_dict])], ignore_index=True)\n",
    "    else:\n",
    "        # Create new dataframe\n",
    "        metrics_df = pd.DataFrame([metrics_dict])\n",
    "    \n",
    "    # Save to CSV\n",
    "    metrics_df.to_csv(filepath, index=False)\n",
    "    print(f\"Metrics saved to {filepath}\")\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Use the function after evaluating your model\n",
    "# Example usage after running the model:\n",
    "save_metrics_to_csv(\"SVM_Linear\", y_val, val_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e145e34",
   "metadata": {},
   "source": [
    "## Custom SVM Implementation (from scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0720ff",
   "metadata": {},
   "source": [
    "### Train and Evaluate Custom SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f86ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (scratch): 0.843010752688172\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8195    0.7968    0.8080      2313\n",
      "           1     0.8589    0.8757    0.8672      3267\n",
      "\n",
      "    accuracy                         0.8430      5580\n",
      "   macro avg     0.8392    0.8363    0.8376      5580\n",
      "weighted avg     0.8426    0.8430    0.8427      5580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªãnh nghƒ©a si√™u tham s·ªë\n",
    "C_value = 1.0  # C n√™n ch·ªçn t·ª´ k·∫øt qu·∫£ GridSearchCV t·ªët nh·∫•t\n",
    "tol_value = 1e-3  # Tolerance th∆∞·ªùng d√πng 1e-4 ho·∫∑c 1e-3\n",
    "max_iter_value = 1000  # S·ªë v√≤ng l·∫∑p t·ªëi ƒëa\n",
    "X = X.head(3000)  # Ch·ªçn 3000 m·∫´u ƒë·∫ßu ti√™n\n",
    "y = y.head(3000)  # Ch·ªçn 3000 nh√£n ƒë·∫ßu ti√™n\n",
    "X_train_array = X.to_numpy()\n",
    "y_train_array = y.to_numpy()\n",
    "# Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh\n",
    "svm_scratch = LinearSVM_Dual(C=C_value, tol=tol_value, max_iter=max_iter_value)\n",
    "svm_scratch.fit(X_train_array, y_train_array)  # S·ª≠ d·ª•ng to√†n b·ªô training data\n",
    "\n",
    "# ƒê√°nh gi√° tr√™n t·∫≠p validation\n",
    "y_pred_scratch = svm_scratch.predict(X_val)\n",
    "print('Accuracy (scratch):', accuracy_score(y_val, y_pred_scratch))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_val, y_pred_scratch, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcceefda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to ../model_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_class0</th>\n",
       "      <th>recall_class0</th>\n",
       "      <th>f1_class0</th>\n",
       "      <th>precision_class1</th>\n",
       "      <th>recall_class1</th>\n",
       "      <th>f1_class1</th>\n",
       "      <th>precision_avg</th>\n",
       "      <th>recall_avg</th>\n",
       "      <th>f1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM_Linear</td>\n",
       "      <td>0.846953</td>\n",
       "      <td>0.833562</td>\n",
       "      <td>0.788154</td>\n",
       "      <td>0.810222</td>\n",
       "      <td>0.855585</td>\n",
       "      <td>0.888583</td>\n",
       "      <td>0.871772</td>\n",
       "      <td>0.844573</td>\n",
       "      <td>0.838368</td>\n",
       "      <td>0.840997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logictics_Regression_lib</td>\n",
       "      <td>0.846057</td>\n",
       "      <td>0.830455</td>\n",
       "      <td>0.789883</td>\n",
       "      <td>0.809661</td>\n",
       "      <td>0.856213</td>\n",
       "      <td>0.885828</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.843334</td>\n",
       "      <td>0.837856</td>\n",
       "      <td>0.840215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree_lib</td>\n",
       "      <td>0.824731</td>\n",
       "      <td>0.810610</td>\n",
       "      <td>0.753134</td>\n",
       "      <td>0.780816</td>\n",
       "      <td>0.833576</td>\n",
       "      <td>0.875421</td>\n",
       "      <td>0.853986</td>\n",
       "      <td>0.822093</td>\n",
       "      <td>0.814278</td>\n",
       "      <td>0.817401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression_Scratch</td>\n",
       "      <td>0.841219</td>\n",
       "      <td>0.832634</td>\n",
       "      <td>0.772157</td>\n",
       "      <td>0.801256</td>\n",
       "      <td>0.846579</td>\n",
       "      <td>0.890113</td>\n",
       "      <td>0.867801</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.834528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM_Linear_scratch</td>\n",
       "      <td>0.843011</td>\n",
       "      <td>0.819475</td>\n",
       "      <td>0.796801</td>\n",
       "      <td>0.807979</td>\n",
       "      <td>0.858901</td>\n",
       "      <td>0.875727</td>\n",
       "      <td>0.867232</td>\n",
       "      <td>0.839188</td>\n",
       "      <td>0.836264</td>\n",
       "      <td>0.837606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  accuracy  precision_class0  recall_class0  \\\n",
       "0                  SVM_Linear  0.846953          0.833562       0.788154   \n",
       "1    logictics_Regression_lib  0.846057          0.830455       0.789883   \n",
       "2           decision_tree_lib  0.824731          0.810610       0.753134   \n",
       "3  LogisticRegression_Scratch  0.841219          0.832634       0.772157   \n",
       "4          SVM_Linear_scratch  0.843011          0.819475       0.796801   \n",
       "\n",
       "   f1_class0  precision_class1  recall_class1  f1_class1  precision_avg  \\\n",
       "0   0.810222          0.855585       0.888583   0.871772       0.844573   \n",
       "1   0.809661          0.856213       0.885828   0.870769       0.843334   \n",
       "2   0.780816          0.833576       0.875421   0.853986       0.822093   \n",
       "3   0.801256          0.846579       0.890113   0.867801       0.839607   \n",
       "4   0.807979          0.858901       0.875727   0.867232       0.839188   \n",
       "\n",
       "   recall_avg    f1_avg  \n",
       "0    0.838368  0.840997  \n",
       "1    0.837856  0.840215  \n",
       "2    0.814278  0.817401  \n",
       "3    0.831135  0.834528  \n",
       "4    0.836264  0.837606  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_metrics_to_csv(\"SVM_Linear_scratch\",y_val, y_pred_scratch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
